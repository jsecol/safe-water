---
title: "CFB zipcode work"
author: "Jim Sheehan"
date: "April 3, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<br>  
  
## 0. Load packages  
  
<br>  

```{r message=FALSE}
library(data.table)
library(readr)
library(dplyr) # some masking of data.table: between, first, last
library(ggplot2)
library(maps) # has some basic vector basemaps
library(zipcode) # for getting lat/lon coordinates where zipcode is available
# library(lubridate)
# library(noncensus) holding off for now, try ZCTA directly, can match to US Census data at that resolution


```

<br>

+ Plan on changing this to access the Google cloud database

## I. Load and clean data

<br>

```{r}
water_systems <- fread("C:/Users/Jim/Files/CFB/JohnMeroth/SDWIS/WATER_SYSTEM.csv", 
                  sep = ",")
```

<br>

#### Small fix of column names (dropping string before "."), and dropping extra empty column:
```{r}
water_systems[, V48 := NULL]

varnames_ws <- colnames(water_systems)
head(varnames_ws)

varnames_ws <- gsub("^.*\\.","",varnames_ws)
colnames(water_systems) <- varnames_ws
# fixed variable names
cat("\n")
varnames_ws


```

<br>

#### Looking for/at duplicates in primary key:
```{r}
water_systems %>% 
  count(PWSID) %>% 
  filter(n > 1)

```

<br>

#### Set primary key:
```{r}
setkey(water_systems, PWSID)
key(water_systems)
```

<br>

#### Zipcode data from census zip code tabulation areas

 + can use these to match to demographics, etc, at a relatively fine scale
 
```{r}
# data.table seems to be harder for .zip, using readr package
zcta <- read_table2("../data/2016_Gaz_zcta_national.zip")

# empty extra column dropped
zcta <- zcta[, -8]

```

<br>

#### Zipcode data from zipcode::zipcode

 + provides some "fill-in"
 
```{r}
data(zipcode)
sum(nchar(zipcode$zip) != 5) # all 5 character length

```

<br>

#### Zipcode clean:
```{r}

# whoa, the zip codes in water_systems are messy:
unique(nchar(water_systems$ZIP_CODE))
nrow(water_systems[nchar(water_systems$ZIP_CODE) != 5 & nchar(water_systems$ZIP_CODE) > 0, ])


water_systems$ZIP_CODE5 <- substr(water_systems$ZIP_CODE, start = 1, stop = 5) 

sum(is.na(water_systems$ZIP_CODE5))

# now using zipcode clean package function (which doesn't fix >5 character zips)
# seems to remove mostly junk (zip codes "", with characters instead of #'s, etc.)
water_systems$ZIP_CODE5 <- clean.zipcodes(water_systems$ZIP_CODE5)

sum(is.na(water_systems$ZIP_CODE5))

water_systems %>% filter(is.na(ZIP_CODE5), ZIP_CODE != "") %>% 
  .$ZIP_CODE

# Fixing one "5496O" should be "54960"

water_systems <- water_systems %>% 
  mutate(ZIP_CODE5 = case_when(ZIP_CODE == "5496O" ~ "54960", 
                               TRUE ~ ZIP_CODE5))


```

<br>

#### Rename some of the columns for zipcode::zipcode prior to join

+ helps distinguish from similar SDWIS variable names, and other lat/lon sources (e.g., zipcode tabulation area centroids for comparison)
```{r}
colnames(zipcode)
colnames(zipcode) <- c("zip", "Rzcpkg_city", "Rzcpkg_state", "Rzcpkg_lat", "Rzcpkg_lon")
colnames(zipcode)

```

<br>

## II. Join data

<br>

+ zcta first

```{r}
merge1 <- left_join(water_systems, zcta, by = c("ZIP_CODE5" = "GEOID"))

sum(is.na(merge1$INTPTLAT))
```


+ now zipcode for NA's 

```{r}
merge1 <- left_join(merge1, zipcode, by = c("ZIP_CODE5" = "zip"))

# create merged lat/lon columns and source column


merge1 <- merge1 %>% mutate(LAT = if_else(is.na(INTPTLAT), Rzcpkg_lat, INTPTLAT), 
                            LON = if_else(is.na(INTPTLONG), Rzcpkg_lon, INTPTLONG),
                            COORD_SRC = case_when(!is.na(INTPTLAT) ~ "zcta",
                                                  is.na(INTPTLAT) & !is.na(Rzcpkg_lat) ~ "rzcpkg"))


sum(is.na(merge1$LAT))

```

<br>

#### Filter and count # w/o coordinates, by PWS_TYPE_CODE (row TRUE)

+ also # unique zipcodes

```{r}
merge1_A <- merge1 %>% filter(PWS_ACTIVITY_CODE == "A")

sum(is.na(merge1_A$LAT))

table(is.na(merge1_A$LAT), merge1_A$PWS_TYPE_CODE)

length(unique(merge1_A$ZIP_CODE5))

```

<br>

#### Export dataset

+ adding city and state from zipcode package, may be useful later (also may be different than water_systems)
```{r}
merge1_A %>% select(PWSID, PWS_TYPE_CODE, ZIP_CODE5, LAT, LON, COORD_SRC, Rzcpkg_state, Rzcpkg_city) %>% 
  write.csv(gzfile("data_export/PWSID_coordinates.csv.gz"), row.names = FALSE)

```

<br>

#### Just making sure

```{r}
checkit <- readr::read_csv("data_export/PWSID_coordinates.csv.gz")

nrow(checkit)

head(checkit)

# number of NA's, the PWSIDs that were not matched
summary(checkit$LAT)
summary(checkit$LON)

# coordinate source when present
table(checkit$COORD_SRC)

rm(checkit)

```

<br>

## III. Exploring things a bit

<br>

this is nice:
https://eriqande.github.io/rep-res-web/lectures/making-maps-with-R.html

```{r fig.height=8, fig.width=8}

states <- map_data("state")

lwr48 <- state.abb[!state.abb %in% c("AK", "HI")]

# panel plot instead of together (some overlap if plot 1 on top of other)

merge1_A_CWS_48 <- merge1_A %>% filter(STATE_CODE %in% c(lwr48, "DC"), 
                                       PWS_TYPE_CODE == "CWS",
                                       GW_SW_CODE %in% c("GW", "SW"),
                                       between(LON, -130, -60 ), 
                                       between(LAT, 25, 50 ))

ggplot(data = states) + 
  geom_polygon(aes(x = long, y = lat, group = group), fill = "white", color = "gray70") + 
  geom_point(data = merge1_A_CWS_48, 
             aes(x = LON, y = LAT, color = GW_SW_CODE), size = 0.8, alpha = 0.75) +
  coord_fixed(1.3) + 
  ggtitle("Zip codes with >= 1 Active CWS by surface and ground water as primary source") + 
  scale_color_manual(values = c("purple", "orange")) + facet_wrap(~GW_SW_CODE, ncol = 1)

```

<br><br><br><br>

# END

***

*In development*

<br>

#### Counting things at/within a distance of zip code coordinate

+ create spatial sp object

```{r}
library(sp)

Coords_CWS <- merge1_A %>% filter(PWS_TYPE_CODE == "CWS") %>% 
  dplyr::select(ZIP_CODE5, LAT, LON, STATE_CODE) %>% unique() %>% na.omit()

dups_zips <- which(duplicated(Coords_CWS$ZIP_CODE5))
dups_zips <- Coords_CWS[dups_zips, ]$ZIP_CODE5

Coords_CWS %>% filter(ZIP_CODE5 %in% dups_zips) %>% 
  arrange(ZIP_CODE5, STATE_CODE)

# so  probably easier to get state via spatial intersection (or drop these, some are potential errors)

# redo

Coords_CWS <- merge1_A %>% filter(PWS_TYPE_CODE == "CWS") %>% 
  dplyr::select(ZIP_CODE5, LAT, LON) %>% unique() %>% na.omit()

geo_prj <- "+proj=longlat +ellps=WGS84"

CWS_A_sp <- sp::SpatialPointsDataFrame(coords = Coords_CWS[,c("LON", "LAT")], 
                           data = Coords_CWS, proj4string = CRS(geo_prj))

plot(CWS_A_sp)
```

+ in this example, trimming to US 48 boundary

*found this for easy way to get US mainland:*

https://grokbase.com/t/r/r-sig-geo/106paa0c7w/how-to-transform-polygons-to-spatialpolygons

```{r}

library(maps)
library(maptools)
usa <- map("usa", plot = FALSE, fill = TRUE)
IDs <- sapply(strsplit(usa$names, ":"), function(x) x[1])
crs <- CRS("+proj=longlat +ellps=WGS84")
sp.usa <- map2SpatialPolygons(usa, IDs=usa$names, proj4string = crs)

mainland <- list(slot(sp.usa, "polygons")[[3]])
sp_mainland <- SpatialPolygons(mainland, proj4string = crs)
str(sp_mainland)
plot(sp_mainland)

```

*crop the zip codes:*

```{r}
CWS_A_sp_main <- CWS_A_sp[sp_mainland,] # easy way to crop!

plot(CWS_A_sp_main, cex = 0.2, col = "gray50")
```

+ get some environmental data (this can take some time and be quite large, here it is being downloaded to a folder created on a local drive; once done it will pull from there if re-run)
  
*following:*  
  
https://gis.stackexchange.com/questions/227585/how-to-use-r-to-extract-data-from-worldclim

```{r}
# worldclim also has future climate available at 2.5, 5, and 10 minutes of a degree; see ?getData

library(raster)

# can get big, so extracting to pre-defined local directory

r <- getData("worldclim", var = "bio", res = 2.5, path = "C:/temp/bioclim")
r

```

+ clean it up a bit and crop it

```{r}
rs <- r[[c(1, 5, 6, 7, 8, 12, 16, 17)]]
names(rs) <- c("TAM","TMAX", "TMIN", "TAR", 
               "TWQ", "PAN", "PWTQ", "PDQ")

# get extent and add a bit of a buffer
mainland_extent <- extent(sp_mainland) + c(-1, 1, -1, 1)

rsc <- crop(rs, mainland_extent)

# TAM (mean annual temp in C * 10)
plot(rsc$TAM)
```

+ get data for the zip codes (note: can be more involved, such as using a buffer; see ?extract)

```{r}
CWS_A_sp_main <- extract(x = rsc$TAM, y = CWS_A_sp_main, sp = TRUE)

head(CWS_A_sp_main)
nrow(CWS_A_sp_main)

# since data uses a scale factor of 10, to get degrees C:
summary(CWS_A_sp_main$TAM)/10

```

+ Make a map of it

```{r}
library(viridis) # some nice color schemes via ggplot2 added function scale_color_viridis

CWS_A_sp_main@data %>% 
  ggplot(aes(x = LON, y = LAT, color = TAM/10)) +
  geom_point(size = 0.8) + 
  scale_color_viridis() +
  ggtitle("Active, CWS zip codes: mean annual temperature (C)")

# saving sp object for use elsewhere (e.g., linking this environmental variable to PWSID)

saveRDS(CWS_A_sp_main, "data_export/Zips_CWS_A_sp_main_TAM.rds")

```

<br>

***

*In development*


#### linking to demographic info (at zcta-level)
https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_17_5YR_DP03&prodType=table

#### getting county
https://stackoverflow.com/questions/13316185/r-convert-zipcode-or-lat-long-to-county


