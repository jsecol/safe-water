---
title: "Spatial join of region 01 (New England) county subdivisions to SDWIS/External data"
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
    toc_depth: 4
---

```{r opts, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "md_files/spatialjoin_r01_cosubs/"
)
```

## Description

Spatial join of water system locations (improved) for epa region 01 to county subdivisions and associated data (US Census and environmental).

Data sources:

1. external: [spatial boundaries: 2018 county subdivisions](https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2018&layergroup=County+Subdivisions), also available [here](https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html)
2. external: SELECTED ECONOMIC CHARACTERISTICS 2013-2017 American Community Survey 5-Year Estimates: [2017  (latest year available at present)](https://factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t)
3. external: [spatial grid: extreme rainfall estimates](http://precip.eas.cornell.edu/)
4. external: [improved pwsid location coordinates in Google Drive](https://drive.google.com/open?id=1oCcKON45B3mmqagA1U964Wl2xz3xwgFXwEMucnIz93w)
5. SDWIS tables: water systems, violations

Coding outline:

1. Load and spatially join pre-processed spatial data (county subdivisions and improved locations data).
    + Join this to SDWIS water systems table data as new table: `joined_df` of water systems with associated spatial data
2. Example modeling use: exploratory logistic regression and heatmap using coliform violations data.


## Load packages

```{r message=FALSE}

library(tidyr)
library(dplyr)
library(sf)
library(fs)
library(readr)
library(data.table)
library(lubridate)
library(jtools)
library(ggplot2)
library(car)

```

## I. Load and join data

### Load spatial boundary data

* Geoprocessing can get pretty involved and files can be large, so working in another GitHub repo [spatial](https://github.com/jsecol/spatial) for the time being
    + loaded using https://raw.githack.com/
    + has US Census data attributes also pre-joined
        + HC01_VC85: median income in 2017
        + HC03_VC161: percent families/people w/past 12 mo. income below poverty level

```{r}

# reprojected to epsg: 26918

epa01_cosub2018 <- 
  st_read("https://raw.githack.com/jsecol/spatial/master/data/epa01_cosub2018.geojson", 
          stringsAsFactors = FALSE) %>% 
  st_transform(26918) %>% filter(TRUE)

st_crs(epa01_cosub2018)

```

+ Join extreme rainfall estimates also from spatial repo

```{r message=FALSE}

raindata <- read_csv("https://raw.githack.com/jsecol/spatial/master/data/epa01_cosub2018_rain.csv")

epa01_cosub2018 <- epa01_cosub2018 %>% 
  left_join(., raindata[, c(1, 4)], by = "GEOID")

```

+ Example chloropleth map to view the boundaries

```{r}

plot(epa01_cosub2018["rpe_1d_1y"], 
     main = "Extreme Precipitation Estimates (1 day/1 year)")

```

### Load locations data

* also from spatial repo for time being
    + used Google Drive packages there

```{r}

epa01_watersystems <- 
  st_read("https://raw.githack.com/jsecol/spatial/master/data/epa01_watersystems.geojson", 
          stringsAsFactors = FALSE) %>% 
  st_transform(26918) %>% filter(TRUE)

st_crs(epa01_cosub2018)

```

### Do spatial join

```{r}

joined_df <- epa01_watersystems %>% 
    st_join(., left = TRUE, epa01_cosub2018) %>% 
    st_drop_geometry()

sum(is.na(joined_df$INTPTLAT))

head(joined_df) %>% print.data.frame()
  
```

* good, although 1 in MA (09) put in NH (33)

```{r}

table(joined_df$PRIMACY_AGENCY_CODE, joined_df$STATEFP)

```

+ try to fix later (update locations sheet on shared drive)

```{r}

joined_df %>% filter(PRIMACY_AGENCY_CODE == "MA", 
                     STATEFP == "33") %>% 
  select(PRIMACY_AGENCY_CODE:NAME) %>% 
  print.data.frame()

```

+ some missing census data

```{r}

joined_df %>% filter(is.na(HC03_VC161) | is.na(HC01_VC85)) %>% 
  select(PRIMACY_AGENCY_CODE, NAME, HC03_VC161, HC01_VC85) %>% 
  distinct() %>% 
  print.data.frame()

```


***


## II. Example modeling use

### Get SDWIS data

+ Assuming it's in "C:/temp/SDWIS.zip"

```{r}

base_dir <- "C:/temp"

path_SDWIS <- paste0(base_dir, "/SDWIS.zip")

SDWIS.zip_names <- grep('\\.csv$', unzip(path_SDWIS, list=TRUE)$Name, 
                           ignore.case=TRUE, value=TRUE)
SDWIS.zip_names

```

+ extraction of relevant tables to a common directory (`overwrite = FALSE`: only if not already present)

```{r}

unzip(path_SDWIS, exdir = paste0(base_dir, "/sdwis_echo"), 
      files = SDWIS.zip_names[c(9, 7)],
      junkpaths = TRUE,
      overwrite = FALSE)

```

+ load (using data.table for speed)

```{r}

# blank field detected, so fill = TRUE
water_system <- fread("C:/temp/sdwis_echo/WATER_SYSTEM.csv", 
                      sep = ",", 
                      colClasses=c("character"),
                      nThread = 1, 
                      fill = TRUE) %>% 
  as_tibble() %>% 
  filter(WATER_SYSTEM.EPA_REGION == "01", WATER_SYSTEM.PWS_ACTIVITY_CODE == "A")

viols <- fread("C:/temp/sdwis_echo/VIOLATION.csv", 
               sep = ",", 
               colClasses=c("character"),
               nThread = 1, 
               fill = TRUE) %>% 
  as_tibble() %>% 
  filter(VIOLATION.EPA_REGION == "01", VIOLATION.PWS_ACTIVITY_CODE == "A")

```

+ convert some fields to date fields

```{r}

viols <- viols %>%
  mutate(VIOLATION.COMPL_PER_BEGIN_DATE = dmy(VIOLATION.COMPL_PER_BEGIN_DATE), 
         VIOLATION.COMPL_PER_END_DATE = dmy(VIOLATION.COMPL_PER_END_DATE), 
         VIOLATION.RTC_DATE = dmy(VIOLATION.RTC_DATE)) %>% 
  filter(TRUE)

```

+ peek at coliform data (note none past 2016 for some reason)

```{r}

viol_coli <- viols %>% filter(VIOLATION.CONTAMINANT_CODE == "3100", 
                              VIOLATION.PWSID %in% epa01_watersystems$PWSID)

table(viol_coli$VIOLATION.PRIMACY_AGENCY_CODE)

```


```{r}

summary(viol_coli$VIOLATION.COMPL_PER_BEGIN_DATE)

table(year(viol_coli$VIOLATION.COMPL_PER_BEGIN_DATE))

```

### Generate dataset

* tabulate years over 2010-2015 period with a health based violation and join to `joined_df` (note that b/c there can be multiple violations per PWSID in one year, reducing that via `distinct` to 1/yr)
    + year range selected b/c no HB viols in 2017 (why?)
    + following PNAS methodology for `sample` (allow only water systems reporting violations as of 2010)
    + 2010 used to get lagged `COLI_HB_FLAG` for 2011, for an analysis using it (2011-2015)


```{r}

sample <- viols %>% 
  filter(year(VIOLATION.COMPL_PER_BEGIN_DATE) <= 2010) %>% 
  .$VIOLATION.PWSID %>% unique()


viol_hb_coli_by_year <- viols %>% 
  filter(VIOLATION.PWSID %in% sample) %>% 
  filter(VIOLATION.CONTAMINANT_CODE == "3100", 
         VIOLATION.IS_HEALTH_BASED_IND == "Y", 
         between(year(VIOLATION.COMPL_PER_BEGIN_DATE), 2010, 2015)) %>% 
  mutate(VIOLYEAR = year(VIOLATION.COMPL_PER_BEGIN_DATE)) %>% 
  select(VIOLATION.PWSID, VIOLYEAR) %>% 
  distinct() %>% 
  mutate(COLI_HB_FLAG = 1) %>% 
  arrange(VIOLATION.PWSID, VIOLYEAR)

# get panel data
viol_hb_coli <- viol_hb_coli_by_year %>% 
  expand(VIOLATION.PWSID, VIOLYEAR) %>% 
  left_join(., viol_hb_coli_by_year, by = c("VIOLATION.PWSID", "VIOLYEAR")) %>% 
  mutate(COLI_HB_FLAG = replace_na(COLI_HB_FLAG, 0))

# get and expand water systems with no violations
viol_nonhb_coli <- viols %>% 
  filter(VIOLATION.PWSID %in% sample) %>% 
  filter(!VIOLATION.PWSID %in% unique(viol_hb_coli$VIOLATION.PWSID)) %>% 
  select(VIOLATION.PWSID) %>% 
  distinct() %>% 
  expand(., VIOLATION.PWSID, VIOLYEAR = 2010:2015) %>% 
  mutate(COLI_HB_FLAG = 0)

# merge them
modeldata1 = bind_rows(viol_hb_coli, viol_nonhb_coli)

# join to joined_df
modeldata1_cosub <- joined_df %>% 
  select(PWSID, PRIMACY_AGENCY_CODE, PWS_TYPE_CODE, GEOID, 
         HC01_VC85, HC03_VC161, rpe_1d_1y) %>% 
  inner_join(., modeldata1, by = c("PWSID" = "VIOLATION.PWSID"))

```

+ add lag variable

```{r}

modeldata1_cosub <- modeldata1_cosub %>% 
  group_by(PWSID) %>% 
  mutate(LAG_1 = lag(COLI_HB_FLAG, n = 1, default = NA)) %>% 
  ungroup()

modeldata1_cosub %>% select(PWSID, GEOID:LAG_1) %>% 
  slice(1:10)

```

### Model 1

#### Examine data

* Explore continuous data
    + skewed, leaving as is for now in model

```{r}

joined_df %>% select(GEOID, HC03_VC161:rpe_1d_1y) %>% 
  pivot_longer(cols = HC03_VC161:rpe_1d_1y, names_to = "variable") %>% 
#  mutate(value = log(value + 1)) %>% 
  ggplot(aes(x = value)) + 
  geom_histogram(na.rm = TRUE, color = "orange", bins = 30) +
  facet_wrap(~variable, scales = "free", ncol = 2)

```

```{r}

round(cor(joined_df[c("HC03_VC161", "HC01_VC85", "rpe_1d_1y")], 
    use = "pairwise.complete.obs"), 2)

```

* Are census data (linearly) correlated?
    + somewhat negative linear trend; but non-linear appears more appropriate

```{r}

cor1 <- round(cor(joined_df[, c("HC03_VC161", "HC01_VC85")], 
    use = "pairwise.complete.obs"), 2)[2]

joined_df %>% select(GEOID, HC01_VC85, HC03_VC161) %>% 
  na.omit() %>% 
  ggplot(aes(x = HC01_VC85, y = HC03_VC161)) +
  geom_point(na.rm = TRUE) +
  xlab("2017 median income") +
  ylab("% poverty") +
  geom_smooth(method = "lm", se = FALSE) +
  coord_cartesian(ylim = c(0, 60)) +
  annotate(geom = "text", x = 150000, y = 30, label = paste0("r = ", cor1),
              color = "blue") +
  geom_smooth(method = "lm", 
              formula = y ~ poly(x, 3, raw=TRUE), 
              colour="red", se = FALSE)

```

#### Apply logistic regression

* Loop to separately model by `PWS_TYPE_CODE` and show summary output 
    + year considered catagorical (2011 = baseline)
    + state CT = baseline
    + poverty, income, and rainfall centered and scaled (mean = 0, sd = 1)

```{r}

PWS_TYPE_CODES <- unique(modeldata1_cosub$PWS_TYPE_CODE)

for(i in 1:length(PWS_TYPE_CODES)){
  data <- modeldata1_cosub %>% na.omit() %>% 
    filter(PWS_TYPE_CODE == PWS_TYPE_CODES[i]) 
  model <- glm(COLI_HB_FLAG ~ 
                 factor(VIOLYEAR) + 
                 PRIMACY_AGENCY_CODE + 
                 scale(HC03_VC161) + 
                 scale(HC01_VC85) + 
                 scale(rpe_1d_1y) +
                 LAG_1,
      data = data, family = binomial(link = "logit"))
  cat("\n\n", "PWS_TYPE_CODE = ", PWS_TYPE_CODES[i], "\n\n")
  print(summ(model))
  print(Anova(model))
#  print(vif(model))
}

```

* Results overview (based on p-values from Type II tests)
    + Year, State, and lag effects throughout
    + For CWS only, a negative relation to the poverty indicator and extreme rainfall estimates

### Heatmap

* **NOTE: All violations data**
    + deriving proportion of PWS having a HB coliform violation in any year

```{r}

COLI_HB_hmdat1 <- viols %>%
  mutate(
    COLI_HB_FLAG =
      case_when(
        VIOLATION.IS_HEALTH_BASED_IND == "Y" &
          VIOLATION.CONTAMINANT_CODE == "3100" ~ 1,
        TRUE ~ 0
      )
  ) %>% 
  select(VIOLATION.PWSID, COLI_HB_FLAG) %>% 
  distinct() %>% 
  pivot_wider(names_from = COLI_HB_FLAG, values_from = COLI_HB_FLAG, 
              names_prefix = "COLI_HB_FLAG_", 
              values_fill = list(COLI_HB_FLAG = 0)) %>% 
  select(-COLI_HB_FLAG_0) %>% 
  inner_join(., joined_df, by = c("VIOLATION.PWSID" = "PWSID")) %>%
  select(GEOID, VIOLATION.PWSID, PWS_TYPE_CODE, COLI_HB_FLAG_1) 


head(COLI_HB_hmdat1)


COLI_HB_hmdat2 <- COLI_HB_hmdat1 %>% 
  group_by(GEOID) %>% 
  summarise(sum_COLI_HB = sum(COLI_HB_FLAG_1), 
            n_PWS = n(), 
            COLI_HB_prp = sum_COLI_HB / n_PWS)

head(COLI_HB_hmdat2)

```


* join to spatial data


```{r}

epa01_cosub2018_hmdat <- COLI_HB_hmdat2 %>% 
  left_join(epa01_cosub2018, ., by = "GEOID")

hist(epa01_cosub2018_hmdat$COLI_HB_prp)

```


* plot heat map


```{r fig.height=7, fig.width=7}

ggplot(epa01_cosub2018_hmdat) +
  geom_sf(aes(fill = COLI_HB_prp)) +
  scale_fill_viridis_c(na.value="transparent") +
  labs(fill = "Proportion of water systems") + 
  ggtitle("Coliform health-based violations per county subdivision")


```


* Some state patterns, e.g., MA vs. CT
    + patterns within states; e.g., MA (northeast vs. rest of state) and CT (eastern vs. western, relatively)


