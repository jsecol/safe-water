---
title: "Spatial join of region 01 (New England) county subdivisions to SDWIS/External data"
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
    toc_depth: 3
---

```{r opts, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "md_files/spatialjoin_r01_cosubs/"
)
```

### Description

Brief description.

Data sources:

1. https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html
2. https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2018&layergroup=County+Subdivisions *(preferred)*
3. SELECTED ECONOMIC CHARACTERISTICS 2013-2017 American Community Survey 5-Year Estimates: 2017 latest year available at 

Coding outline:

1. 
2. 
3. 
4. 



### Load packages

```{r message=FALSE}

# # googlesheets4 can work with googledrive to get a specific worksheet in a google sheet
# # it's currently in development, get devtools, uncomment and run this first if needed:
# devtools::install_github("tidyverse/googlesheets4")

library(dplyr)
library(sf)
library(fs)
library(readr)
library(data.table)
library(lubridate)
library(jtools)

```


### Load spatial boundary data

* geoprocessing can get pretty involved and files can be large, so working in another GitHub repo for the time being
    + loaded using https://raw.githack.com/
    + has US Census data attributes also pre-joined (again a bit too involved)

```{r}

# reprojected to epsg: 26918

epa01_cosub2018 <- 
  st_read("https://raw.githack.com/jsecol/spatial/master/data/epa01_cosub2018.geojson", 
          stringsAsFactors = FALSE) %>% 
  st_transform(26918) %>% filter(TRUE)

st_crs(epa01_cosub2018)

```


```{r}
plot(epa01_cosub2018["HC01_VC85"], main = "HC01_VC85: median income in 2017") 
```


### Load locations data

* also from spatial repo
    + from google  sheet

```{r}

epa01_watersystems <- 
  st_read("https://raw.githack.com/jsecol/spatial/master/data/epa01_watersystems.geojson", 
          stringsAsFactors = FALSE) %>% 
  st_transform(26918) %>% filter(TRUE)

st_crs(epa01_cosub2018)

```

### Do spatial join

```{r}

joined_df <- epa01_watersystems %>% 
    st_join(., left = TRUE, epa01_cosub2018) %>% 
    st_drop_geometry()

sum(is.na(joined_df$INTPTLAT))

head(joined_df)
  
```

* pretty good, but 1 in MA (09) put in NH (33)

```{r}

table(joined_df$PRIMACY_AGENCY_CODE, joined_df$STATEFP)

```

+ try to fix later (update locations sheet on shared drive)

```{r}

joined_df %>% filter(PRIMACY_AGENCY_CODE == "MA", 
                     STATEFP == "33")

```

```{r}

joined_df %>% filter(is.na(HC03_VC161) | is.na(HC01_VC85))

```


***

### Example modeling use

+ Get SDWIS data

```{r}

base_dir <- "C:/temp"

path_SDWIS <- paste0(base_dir, "/SDWIS.zip")

SDWIS.zip_names <- grep('\\.csv$', unzip(path_SDWIS, list=TRUE)$Name, 
                           ignore.case=TRUE, value=TRUE)
SDWIS.zip_names

```

+ extraction to a common directory (`overwrite = FALSE`: only if not already present)

```{r}

unzip(path_SDWIS, exdir = paste0(base_dir, "/sdwis_echo"), 
      files = SDWIS.zip_names[c(9, 7)],
      junkpaths = TRUE,
      overwrite = FALSE)

```

+ load (using data.table for speed)

```{r}

# blank field detected, so fill = TRUE
water_system <- fread("C:/temp/sdwis_echo/WATER_SYSTEM.csv", 
                      sep = ",", 
                      colClasses=c("character"),
                      nThread = 1, 
                      fill = TRUE) %>% 
  as_tibble() %>% 
  filter(WATER_SYSTEM.EPA_REGION == "01", WATER_SYSTEM.PWS_ACTIVITY_CODE == "A")

viols <- fread("C:/temp/sdwis_echo/VIOLATION.csv", 
               sep = ",", 
               colClasses=c("character"),
               nThread = 1, 
               fill = TRUE) %>% 
  as_tibble() %>% 
  filter(VIOLATION.EPA_REGION == "01", VIOLATION.PWS_ACTIVITY_CODE == "A")


```

+ convert some fields to date fields

```{r}

viols <- viols %>%
  mutate(VIOLATION.COMPL_PER_BEGIN_DATE = dmy(VIOLATION.COMPL_PER_BEGIN_DATE), 
         VIOLATION.COMPL_PER_END_DATE = dmy(VIOLATION.COMPL_PER_END_DATE), 
         VIOLATION.RTC_DATE = dmy(VIOLATION.RTC_DATE)) %>% 
  filter(TRUE)

```

+ get coliform data

```{r}

viol_coli <- viols %>% filter(VIOLATION.CONTAMINANT_CODE == "3100", 
                              VIOLATION.PWSID %in% epa01_watersystems$PWSID)


table(viol_coli$VIOLATION.PRIMACY_AGENCY_CODE)

summary(viol_coli$VIOLATION.COMPL_PER_BEGIN_DATE)

```

+ reduce to counts and join all to location/cosub data

```{r}

viol_coli_n <- viol_coli %>% 
  filter(VIOLATION.IS_HEALTH_BASED_IND == "Y", 
         between(year(VIOLATION.COMPL_PER_BEGIN_DATE), 2013, 2017)) %>% 
  group_by(VIOLATION.PWSID) %>% 
  tally()

head(viol_coli_n)

joined_df %>% 
  left_join(., viol_coli_n, by = c("PWSID" = "VIOLATION.PWSID")) %>% 
  mutate(n = tidyr::replace_na(n, 0)) %>% slice(1:6)

```

+ are census data (linearly) correlated?

```{r}
plot(HC03_VC161 ~ HC01_VC85, joined_df)

round(cor(joined_df[, c("HC03_VC161", "HC01_VC85")], 
    use = "pairwise.complete.obs"), 2)

```

*somewhat*

1. get good pwsid sample

  + hurdle 1: how to identify pwsid has/doesn't have prior violation (if no prior, was it in existence?? - clean history issue: would love to be able to identify "clean" pwsid's say for 10 year prior, but don't know when pwsid founded. Seems possible that the first time a water system gets in the sdwis data is the first time it has any violation data, not how long it's been out there)
  
  + solution 1: only use pwsid if it has (any) data in violations prior to a year, produces a decent sample size that, e.g., based on modeling 2017 as outcome, has at least a 5-year prior history
  

```{r}

viols_all_5yrs_n <- viols %>%
  filter(VIOLATION.PWSID %in% epa01_watersystems$PWSID,
         year(VIOLATION.COMPL_PER_BEGIN_DATE) <= 2012) %>%
  mutate(CPBD_YEAR = year(VIOLATION.COMPL_PER_BEGIN_DATE)) %>% 
  group_by(VIOLATION.PWSID) %>% 
  summarise(YEAR_N = length(unique(CPBD_YEAR)))

head(viols_all_5yrs_n)

```

+ Join the coliform HB back to this, and model

```{r}

modeldata <- viol_coli %>% 
  filter(VIOLATION.IS_HEALTH_BASED_IND == "Y", 
         between(year(VIOLATION.COMPL_PER_BEGIN_DATE), 2013, 2017)) %>% 
  select(VIOLATION.PWSID) %>% 
  distinct() %>% 
  mutate(COLI_HB_FLAG = 1) %>% 
  left_join(viols_all_5yrs_n, ., by = "VIOLATION.PWSID") %>% 
  mutate(COLI_HB_FLAG = tidyr::replace_na(COLI_HB_FLAG, 0))


modeldata <- joined_df %>% 
  select(PWSID, PWS_TYPE_CODE, PRIMACY_AGENCY_CODE, 
         NAME, GEOID, HC03_VC161, HC01_VC85) %>% 
  left_join(modeldata, ., by = c("VIOLATION.PWSID" = "PWSID"))

head(modeldata)

```

+ summary stats

```{r}

modeldata %>%
  group_by(PWS_TYPE_CODE, COLI_HB_FLAG) %>%
  tally() %>%
  tidyr::pivot_wider(names_from = COLI_HB_FLAG,
                     values_from = n,
                     names_prefix = "COLI_HB_FLAG_") %>%
  mutate(COLI_HB_prp = round(COLI_HB_FLAG_1 /
                               (COLI_HB_FLAG_0 + COLI_HB_FLAG_1), 2))
  
```


```{r}

modeldata %>%
  group_by(PRIMACY_AGENCY_CODE, COLI_HB_FLAG) %>%
  tally() %>%
  tidyr::pivot_wider(names_from = COLI_HB_FLAG,
                     values_from = n,
                     names_prefix = "COLI_HB_FLAG_") %>%
  mutate(COLI_HB_prp = round(COLI_HB_FLAG_1 /
                               (COLI_HB_FLAG_0 + COLI_HB_FLAG_1), 2))
  
```


```{r}

modeldata2 <- modeldata %>% filter(PWS_TYPE_CODE == "CWS") %>% 
  group_by(PRIMACY_AGENCY_CODE, GEOID, COLI_HB_FLAG) %>% 
  tally() %>% 
  tidyr::pivot_wider(names_from = COLI_HB_FLAG,
                     values_from = n,
                     names_prefix = "COLI_HB_FLAG_",
                     values_fill = list(n = 0))  %>% 
  mutate(COLI_HB_prp = round(COLI_HB_FLAG_1 / 
                               (COLI_HB_FLAG_0 + COLI_HB_FLAG_1), 2), 
         PWS_N = COLI_HB_FLAG_0 + COLI_HB_FLAG_1)

modeldata2 <- modeldata2 %>% 
  left_join(., st_drop_geometry(epa01_cosub2018), by = "GEOID")

head(modeldata2)

```


+ logistic regression

```{r}

PWS_TYPE_CODES <- unique(modeldata$PWS_TYPE_CODE)

for(i in 1:length(PWS_TYPE_CODES)){
  data <- modeldata %>% filter(PWS_TYPE_CODE == PWS_TYPE_CODES[i]) 
  model <- glm(COLI_HB_FLAG ~ PRIMACY_AGENCY_CODE + HC03_VC161,
      data = data, family = binomial(link = "logit"))
  cat("\n\n", "PWS_TYPE_CODE = ", PWS_TYPE_CODES[i], "\n\n")
  print(summ(model))
}
  

```

+ `PWS_TYPE == "CWS"`

```{r}

model2 <- glm(cbind(COLI_HB_FLAG_1, COLI_HB_FLAG_0) ~ 
                PRIMACY_AGENCY_CODE + 
                HC03_VC161,
             data = modeldata2, family = binomial(link = "logit"))
summ(model2)

```

+ mapping

```{r}

hist(epa01_cosub2018$HC03_VC161)

```



```{r}

plot(epa01_cosub2018["HC03_VC161"], 
     breaks = c(0, 2, 4, 6, 8, 10, 15, 20, 25,
                max(epa01_cosub2018$HC03_VC161, na.rm = TRUE)))

```



```{r}
viol_coli_n_all1 <- viol_coli %>% 
  filter(VIOLATION.IS_HEALTH_BASED_IND == "Y") %>% 
  group_by(VIOLATION.PWSID) %>% 
  tally() %>% 
  mutate(n = 1)

# viol_coli_n_all1

epa01_cosub2018_2 <- joined_df %>% 
  left_join(., viol_coli_n_all1, by = c("PWSID" = "VIOLATION.PWSID")) %>% 
  mutate(n = tidyr::replace_na(n, 0)) %>% 
  group_by(GEOID, n) %>% 
  tally() %>% 
  tidyr::pivot_wider(names_from = n, 
                     values_from = nn, 
                     names_prefix = "COLI_HB_",
                     values_fill = list(nn = 0)) %>% 
  mutate(COLI_HB_PRP = COLI_HB_1 / (COLI_HB_1 + COLI_HB_0)) %>% 
  left_join(epa01_cosub2018, ., by = "GEOID")

```



```{r}

plot(epa01_cosub2018_2["COLI_HB_PRP"])

```




***

### MISC


+ Combine them (join points state by state)

see: 
https://ryanpeek.github.io/mapping-in-R-workshop/vig_spatial_joins.html

```{r}

# # Note: this skips PRIMACY_AGENCY_CODE "01", only 1 so will do them later
# 
# state_byfips <- unique(epa01_cosub2018$STATEFP)
# 
# joined_list <- list()
# 
# for(i in 1:length(state_byfips)) {
#   joined <- locations_pts %>% 
#     filter(PRIMACY_AGENCY_CODE == state_byfips[i]) %>% 
#     st_join(., left = TRUE, shp_list[[state_byfips[i]]]) %>% 
#     st_drop_geometry()
#   joined_list[[i]] <- joined
#   
# }
# 
# names(joined_list) <- state_byfips
# 
# joined_df <- do.call(bind_rows, joined_list)
# 
# # check if any not matched
# sum(is.na(joined_df$INTPTLAT))
# 
# joined_df %>% filter(is.na(joined_df$INTPTLAT))
# 
# epa01_watersystems %>% filter(PWSID == "MA2115001")

# 42.70396, -71.60161 appears to be bad, over border in NH

```

+ Export

```{r}

# # put in github data folder eventually?
# 
# joined_df %>% 
#   select(PRIMACY_AGENCY_CODE:PWSID, GEOID:NAME) %>% 
#   head()
# 
# dir_create("C:/temp/CFB/data/processed")
# 
# joined_df %>% write_csv("C:/temp/CFB/data/processed/r01_pwsid_cosub.csv")

```



