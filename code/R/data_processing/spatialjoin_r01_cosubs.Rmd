---
title: "Spatial join of region 01 (New England) county subdivisions to SDWIS/External data"
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
    toc_depth: 3
---

```{r opts, echo = FALSE}
knitr::opts_chunk$set(
  fig.path = "md_files/spatialjoin_r01_cosubs/"
)
```

### Description

Spatial join of water system locations (improved) for epa region 01 to county subdivisions and associated data (US Census and environmental).

Data sources:

1. external: [spatial boundaries: 2018 county subdivisions](https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2018&layergroup=County+Subdivisions), also available [here](https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html)
2. external: SELECTED ECONOMIC CHARACTERISTICS 2013-2017 American Community Survey 5-Year Estimates: [2017  (latest year available at present)](https://factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t)
3. external: [spatial grid: extreme rainfall projections](http://precip.eas.cornell.edu/)
4. external: [improved pwsid location coordinates in Google Drive](https://drive.google.com/open?id=1oCcKON45B3mmqagA1U964Wl2xz3xwgFXwEMucnIz93w)
5. SDWIS tables: water systems, violations

Coding outline:

1. Load and spatially join pre-processed spatial data (county subdivisions and improved locations data).
2. Join this to SDWIS water systems table data.
    + new table: `joined_df` of water systems with associated spatial data
3. Example modeling use: exploratory logistic regression and hotspot analysis using coliform violations data.


### Load packages

```{r message=FALSE}

library(tidyr)
library(dplyr)
library(sf)
library(fs)
library(readr)
library(data.table)
library(lubridate)
library(jtools)
library(ggplot2)
# library(reticulate) # allows python code; e.g., US Census API if decide to use it here

```



### Load spatial boundary data

* geoprocessing can get pretty involved and files can be large, so working in another GitHub repo for the time being
    + loaded using https://raw.githack.com/
    + has US Census data attributes also pre-joined
        + HC01_VC85: median income in 2017
        + HC03_VC161: percent families/people w/past 12 mo. income below poverty level

```{r}

# reprojected to epsg: 26918

epa01_cosub2018 <- 
  st_read("https://raw.githack.com/jsecol/spatial/master/data/epa01_cosub2018.geojson", 
          stringsAsFactors = FALSE) %>% 
  st_transform(26918) %>% filter(TRUE)

st_crs(epa01_cosub2018)

```

+ example chloropleth map to view the boundaries (some missing data, probably low population)

```{r}
plot(epa01_cosub2018["HC01_VC85"], main = "HC01_VC85: median income in 2017") 
```


### Load locations data

* also from spatial repo for time being
    + used Google Drive packages there

```{r}

epa01_watersystems <- 
  st_read("https://raw.githack.com/jsecol/spatial/master/data/epa01_watersystems.geojson", 
          stringsAsFactors = FALSE) %>% 
  st_transform(26918) %>% filter(TRUE)

st_crs(epa01_cosub2018)

```

### Do spatial join

```{r}

joined_df <- epa01_watersystems %>% 
    st_join(., left = TRUE, epa01_cosub2018) %>% 
    st_drop_geometry()

sum(is.na(joined_df$INTPTLAT))

head(joined_df) %>% print.data.frame()
  
```

* good, although 1 in MA (09) put in NH (33)

```{r}

table(joined_df$PRIMACY_AGENCY_CODE, joined_df$STATEFP)

```

+ try to fix later (update locations sheet on shared drive)

```{r}

joined_df %>% filter(PRIMACY_AGENCY_CODE == "MA", 
                     STATEFP == "33") %>% 
  select(PRIMACY_AGENCY_CODE:NAME) %>% 
  print.data.frame()

```

+ some missing census data

```{r}

joined_df %>% filter(is.na(HC03_VC161) | is.na(HC01_VC85)) %>% 
  select(PRIMACY_AGENCY_CODE, PWSID, NAME, HC03_VC161, HC01_VC85) %>% 
  print.data.frame()

```


***

### Example modeling use

+ Get SDWIS data (assuming it's in "C:/temp/SDWIS.zip")

```{r}

base_dir <- "C:/temp"

path_SDWIS <- paste0(base_dir, "/SDWIS.zip")

SDWIS.zip_names <- grep('\\.csv$', unzip(path_SDWIS, list=TRUE)$Name, 
                           ignore.case=TRUE, value=TRUE)
SDWIS.zip_names

```

+ extraction of relevant tables to a common directory (`overwrite = FALSE`: only if not already present)

```{r}

unzip(path_SDWIS, exdir = paste0(base_dir, "/sdwis_echo"), 
      files = SDWIS.zip_names[c(9, 7)],
      junkpaths = TRUE,
      overwrite = FALSE)

```

+ load (using data.table for speed)

```{r}

# blank field detected, so fill = TRUE
water_system <- fread("C:/temp/sdwis_echo/WATER_SYSTEM.csv", 
                      sep = ",", 
                      colClasses=c("character"),
                      nThread = 1, 
                      fill = TRUE) %>% 
  as_tibble() %>% 
  filter(WATER_SYSTEM.EPA_REGION == "01", WATER_SYSTEM.PWS_ACTIVITY_CODE == "A")

viols <- fread("C:/temp/sdwis_echo/VIOLATION.csv", 
               sep = ",", 
               colClasses=c("character"),
               nThread = 1, 
               fill = TRUE) %>% 
  as_tibble() %>% 
  filter(VIOLATION.EPA_REGION == "01", VIOLATION.PWS_ACTIVITY_CODE == "A")


```

+ convert some fields to date fields

```{r}

viols <- viols %>%
  mutate(VIOLATION.COMPL_PER_BEGIN_DATE = dmy(VIOLATION.COMPL_PER_BEGIN_DATE), 
         VIOLATION.COMPL_PER_END_DATE = dmy(VIOLATION.COMPL_PER_END_DATE), 
         VIOLATION.RTC_DATE = dmy(VIOLATION.RTC_DATE)) %>% 
  filter(TRUE)

```

+ peek at coliform data (note none past 2016 for some reason)

```{r}

viol_coli <- viols %>% filter(VIOLATION.CONTAMINANT_CODE == "3100", 
                              VIOLATION.PWSID %in% epa01_watersystems$PWSID)

table(viol_coli$VIOLATION.PRIMACY_AGENCY_CODE)

summary(viol_coli$VIOLATION.COMPL_PER_BEGIN_DATE)

table(year(viol_coli$VIOLATION.COMPL_PER_BEGIN_DATE))

```

* tabulate years over 2010-2015 period with a health based violation and join to `joined_df` (note that b/c there can be multiple violations per PWSID in one year, reducing that via `distinct` to 1/yr)
    + year range selected b/c no HB viols in 2017 (why?)
    + following PNAS methodology for `sample` (allow only water systems reporting violations as of 2010)
    + 2010 used to get lagged `COLI_HB_FLAG` for 2011, for an analysis using it (2011-2015)


```{r}
sample <- viols %>% 
  filter(year(VIOLATION.COMPL_PER_BEGIN_DATE) <= 2010) %>% 
  .$VIOLATION.PWSID %>% unique()


viol_hb_coli_by_year <- viols %>% 
  filter(VIOLATION.PWSID %in% sample) %>% 
  filter(VIOLATION.CONTAMINANT_CODE == "3100", 
         VIOLATION.IS_HEALTH_BASED_IND == "Y", 
         between(year(VIOLATION.COMPL_PER_BEGIN_DATE), 2010, 2015)) %>% 
  mutate(VIOLYEAR = year(VIOLATION.COMPL_PER_BEGIN_DATE)) %>% 
  select(VIOLATION.PWSID, VIOLYEAR) %>% 
  distinct() %>% 
  mutate(COLI_HB_FLAG = 1) %>% 
  arrange(VIOLATION.PWSID, VIOLYEAR)

head(viol_hb_coli_by_year) 

# get panel data
viol_hb_coli <- viol_hb_coli_by_year %>% 
  expand(VIOLATION.PWSID, VIOLYEAR) %>% 
  left_join(., viol_hb_coli_by_year, by = c("VIOLATION.PWSID", "VIOLYEAR")) %>% 
  mutate(COLI_HB_FLAG = replace_na(COLI_HB_FLAG, 0))

head(viol_hb_coli, 10) 

# get and expand water systems with no violations
viol_nonhb_coli <- viols %>% 
  filter(VIOLATION.PWSID %in% sample) %>% 
  filter(!VIOLATION.PWSID %in% unique(viol_hb_coli$VIOLATION.PWSID)) %>% 
  select(VIOLATION.PWSID) %>% 
  distinct() %>% 
  expand(., VIOLATION.PWSID, VIOLYEAR = 2010:2015) %>% 
  mutate(COLI_HB_FLAG = 0)

# merge them
modeldata1 = bind_rows(viol_hb_coli, viol_nonhb_coli)

# join to joined_df
modeldata1_cosub <- joined_df %>% 
  select(PWSID, PRIMACY_AGENCY_CODE, PWS_TYPE_CODE, GEOID, HC01_VC85, HC03_VC161) %>% 
  inner_join(., modeldata1, by = c("PWSID" = "VIOLATION.PWSID"))

head(modeldata1_cosub, 10)

```

+ add lag variable

```{r}

modeldata1_cosub <- modeldata1_cosub %>% 
  group_by(PWSID) %>% 
  mutate(LAG_1 = lag(COLI_HB_FLAG, n = 1, default = NA)) %>% 
  ungroup()

modeldata1_cosub %>% select(PWSID, GEOID:LAG_1) %>% 
  slice(1:10)

```

### Model 1

+ separate by `PWS_TYPE_CODE`
+ year considered catagorical (2011 = baseline)
+ state CT = baseline


```{r}

joined_df %>% select(GEOID, HC03_VC161:HC01_VC85) %>% 
  pivot_longer(cols = HC03_VC161:HC01_VC85, names_to = "variable") %>% 
#  mutate(value = log(value + 1)) %>% 
  ggplot(aes(x = value)) + 
  geom_histogram(na.rm = TRUE, color = "orange", bins = 30) +
  facet_wrap(~variable, scales = "free")

```

+ poverty more strongly skewed, leaving as is for now in model
+ poverty and income centered and scaled (mean = 0, sd = 1)

```{r}

PWS_TYPE_CODES <- unique(modeldata1_cosub$PWS_TYPE_CODE)

for(i in 1:length(PWS_TYPE_CODES)){
  data <- modeldata1_cosub %>% na.omit() %>% 
    filter(PWS_TYPE_CODE == PWS_TYPE_CODES[i]) 
  model <- glm(COLI_HB_FLAG ~ 
                 factor(VIOLYEAR) + 
                 PRIMACY_AGENCY_CODE + 
                 scale(HC03_VC161) + 
                 scale(HC01_VC85) + 
                 LAG_1,
      data = data, family = binomial(link = "logit"))
  cat("\n\n", "PWS_TYPE_CODE = ", PWS_TYPE_CODES[i], "\n\n")
  print(summ(model))
}

```

+ are census data (linearly) correlated?

```{r}

cor1 <- round(cor(joined_df[, c("HC03_VC161", "HC01_VC85")], 
    use = "pairwise.complete.obs"), 2)[2]

joined_df %>% select(GEOID, HC01_VC85, HC03_VC161) %>% 
  na.omit() %>% 
  ggplot(aes(x = HC01_VC85, y = HC03_VC161)) +
  geom_point(na.rm = TRUE) +
  xlab("2017 median income") +
  ylab("% poverty") +
  geom_smooth(method = "lm", se = FALSE) +
  coord_cartesian(ylim = c(0, 60)) +
  annotate(geom = "text", x = 150000, y = 30, label = paste0("r = ", cor1),
              color = "blue") +
  geom_smooth(method = "lm", 
              formula = y ~ poly(x, 3, raw=TRUE), 
              colour="red", se = FALSE)

```

*linear fit is moderate, negative; but non-linear appears more appropriate*


### Hotspot analysis

```{r}

```







































1. get good pwsid sample

  + hurdle 1: how to identify pwsid has/doesn't have prior violation (if no prior, was it in existence?? - clean history issue: would love to be able to identify "clean" pwsid's say for 10 year prior, but don't know when pwsid founded. Seems possible that the first time a water system gets in the sdwis data is the first time it has any violation data, not how long it's been out there)
  
  + solution 1: only use pwsid if it has (any) data in violations prior to a year, produces a decent sample size that, e.g., based on modeling 2017 as outcome, has at least a 5-year prior history
  

```{r}

viols_all_5yrs_n <- viols %>%
  filter(VIOLATION.PWSID %in% epa01_watersystems$PWSID,
         year(VIOLATION.COMPL_PER_BEGIN_DATE) <= 2012) %>%
  mutate(CPBD_YEAR = year(VIOLATION.COMPL_PER_BEGIN_DATE)) %>% 
  group_by(VIOLATION.PWSID) %>% 
  summarise(YEAR_N = length(unique(CPBD_YEAR)))

head(viols_all_5yrs_n)

```

+ Join the coliform HB back to this, and model

```{r}

modeldata <- viol_coli %>% 
  filter(VIOLATION.IS_HEALTH_BASED_IND == "Y", 
         between(year(VIOLATION.COMPL_PER_BEGIN_DATE), 2013, 2017)) %>% 
  select(VIOLATION.PWSID) %>% 
  distinct() %>% 
  mutate(COLI_HB_FLAG = 1) %>% 
  left_join(viols_all_5yrs_n, ., by = "VIOLATION.PWSID") %>% 
  mutate(COLI_HB_FLAG = tidyr::replace_na(COLI_HB_FLAG, 0))


modeldata <- joined_df %>% 
  select(PWSID, PWS_TYPE_CODE, PRIMACY_AGENCY_CODE, 
         NAME, GEOID, HC03_VC161, HC01_VC85) %>% 
  left_join(modeldata, ., by = c("VIOLATION.PWSID" = "PWSID"))

head(modeldata)

```

+ summary stats

```{r}

modeldata %>%
  group_by(PWS_TYPE_CODE, COLI_HB_FLAG) %>%
  tally() %>%
  tidyr::pivot_wider(names_from = COLI_HB_FLAG,
                     values_from = n,
                     names_prefix = "COLI_HB_FLAG_") %>%
  mutate(COLI_HB_prp = round(COLI_HB_FLAG_1 /
                               (COLI_HB_FLAG_0 + COLI_HB_FLAG_1), 2))
  
```


```{r}

modeldata %>%
  group_by(PRIMACY_AGENCY_CODE, COLI_HB_FLAG) %>%
  tally() %>%
  tidyr::pivot_wider(names_from = COLI_HB_FLAG,
                     values_from = n,
                     names_prefix = "COLI_HB_FLAG_") %>%
  mutate(COLI_HB_prp = round(COLI_HB_FLAG_1 /
                               (COLI_HB_FLAG_0 + COLI_HB_FLAG_1), 2))
  
```


```{r}

modeldata2 <- modeldata %>% filter(PWS_TYPE_CODE == "CWS") %>% 
  group_by(PRIMACY_AGENCY_CODE, GEOID, COLI_HB_FLAG) %>% 
  tally() %>% 
  tidyr::pivot_wider(names_from = COLI_HB_FLAG,
                     values_from = n,
                     names_prefix = "COLI_HB_FLAG_",
                     values_fill = list(n = 0))  %>% 
  mutate(COLI_HB_prp = round(COLI_HB_FLAG_1 / 
                               (COLI_HB_FLAG_0 + COLI_HB_FLAG_1), 2), 
         PWS_N = COLI_HB_FLAG_0 + COLI_HB_FLAG_1)

modeldata2 <- modeldata2 %>% 
  left_join(., st_drop_geometry(epa01_cosub2018), by = "GEOID")

head(modeldata2)

```


+ logistic regression

```{r}

PWS_TYPE_CODES <- unique(modeldata$PWS_TYPE_CODE)

for(i in 1:length(PWS_TYPE_CODES)){
  data <- modeldata %>% filter(PWS_TYPE_CODE == PWS_TYPE_CODES[i]) 
  model <- glm(COLI_HB_FLAG ~ PRIMACY_AGENCY_CODE + HC03_VC161,
      data = data, family = binomial(link = "logit"))
  cat("\n\n", "PWS_TYPE_CODE = ", PWS_TYPE_CODES[i], "\n\n")
  print(summ(model))
}
  

```

+ `PWS_TYPE == "CWS"`

```{r}

model2 <- glm(cbind(COLI_HB_FLAG_1, COLI_HB_FLAG_0) ~ 
                PRIMACY_AGENCY_CODE + 
                HC03_VC161,
             data = modeldata2, family = binomial(link = "logit"))
summ(model2)

```

+ mapping

```{r}

hist(epa01_cosub2018$HC03_VC161)

```



```{r}

plot(epa01_cosub2018["HC03_VC161"], 
     breaks = c(0, 2, 4, 6, 8, 10, 15, 20, 25,
                max(epa01_cosub2018$HC03_VC161, na.rm = TRUE)))

```



```{r}
viol_coli_n_all1 <- viol_coli %>% 
  filter(VIOLATION.IS_HEALTH_BASED_IND == "Y") %>% 
  group_by(VIOLATION.PWSID) %>% 
  tally() %>% 
  mutate(n = 1)

# viol_coli_n_all1

epa01_cosub2018_2 <- joined_df %>% 
  left_join(., viol_coli_n_all1, by = c("PWSID" = "VIOLATION.PWSID")) %>% 
  mutate(n = tidyr::replace_na(n, 0)) %>% 
  group_by(GEOID, n) %>% 
  tally() %>% 
  tidyr::pivot_wider(names_from = n, 
                     values_from = nn, 
                     names_prefix = "COLI_HB_",
                     values_fill = list(nn = 0)) %>% 
  mutate(COLI_HB_PRP = COLI_HB_1 / (COLI_HB_1 + COLI_HB_0)) %>% 
  left_join(epa01_cosub2018, ., by = "GEOID")

```



```{r}

plot(epa01_cosub2018_2["COLI_HB_PRP"])

```




***

### MISC


+ Combine them (join points state by state)

see: 
https://ryanpeek.github.io/mapping-in-R-workshop/vig_spatial_joins.html

```{r}

# # Note: this skips PRIMACY_AGENCY_CODE "01", only 1 so will do them later
# 
# state_byfips <- unique(epa01_cosub2018$STATEFP)
# 
# joined_list <- list()
# 
# for(i in 1:length(state_byfips)) {
#   joined <- locations_pts %>% 
#     filter(PRIMACY_AGENCY_CODE == state_byfips[i]) %>% 
#     st_join(., left = TRUE, shp_list[[state_byfips[i]]]) %>% 
#     st_drop_geometry()
#   joined_list[[i]] <- joined
#   
# }
# 
# names(joined_list) <- state_byfips
# 
# joined_df <- do.call(bind_rows, joined_list)
# 
# # check if any not matched
# sum(is.na(joined_df$INTPTLAT))
# 
# joined_df %>% filter(is.na(joined_df$INTPTLAT))
# 
# epa01_watersystems %>% filter(PWSID == "MA2115001")

# 42.70396, -71.60161 appears to be bad, over border in NH

```

+ Export

```{r}

# # put in github data folder eventually?
# 
# joined_df %>% 
#   select(PRIMACY_AGENCY_CODE:PWSID, GEOID:NAME) %>% 
#   head()
# 
# dir_create("C:/temp/CFB/data/processed")
# 
# joined_df %>% write_csv("C:/temp/CFB/data/processed/r01_pwsid_cosub.csv")

```



